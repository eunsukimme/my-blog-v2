---
title: KNN(K-Nearest Neighbors) ì•Œê³ ë¦¬ì¦˜ ê°œë…ì •ë¦¬
summary: K ë²ˆì§¸ ì´ì›ƒì„ ì°¾ëŠ” KNN ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ì„œ ì•Œì•„ë´…ì‹œë‹¤
date: '2019-10-20T14:00:00.000Z'
draft: false
slug: 'understanding-KNN'
category: Machine Learning
tags:
  - TIL
  - Machine Learning
  - Python
---

K-Nearest Neightbors(KNN)ì€ classification ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. í•µì‹¬ì€ ë¹„ìŠ·í•œ ì†ì„±(ì¹´í…Œê³ ë¦¬)ì„ ê°–ëŠ” ë°ì´í„°ë¼ë¦¬ ê°€ê¹Œì´ì— ìœ„ì¹˜í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

<img
  width="680"
  src="https://s3.amazonaws.com/codecademy-content/courses/learn-knn/nearest_neighbor.gif"
/>

ìœ„ ê·¸ë¦¼ì€ ì¢Œí‘œì¶•ì—ì„œ í° ì ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì´ì›ƒí•œ ì ì˜ ê°¯ìˆ˜ë¥¼ Kë¼ê³  í•˜ê³ , ì´ë¥¼ 1ë¶€í„° 5ê¹Œì§€ ëŠ˜ë ¤ë‚˜ê°€ê³  ìˆìŠµë‹ˆë‹¤. ë™ì‹œì— ì¸ì ‘í•œ ì ì˜ ìƒ‰ê¹”ì— ë”°ë¼ì„œ í° ì ì—ê²Œ ë¶€ì—¬í•  ìˆ˜ ìˆëŠ” ìƒ‰ì„ ì˜ˆì¸¡í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ì›ƒí•œ ì ì˜ ê°¯ìˆ˜ê°€ 2ê°€ì§€ëŠ” Green ì´ë¼ê³  ì˜ˆì¸¡í•˜ì§€ë§Œ, 5ê°€ ë˜ì—ˆì„ ë•ŒëŠ” Redë¡œ ì˜ˆì¸¡í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ì›ƒí•œ ì ì˜ ê°¯ìˆ˜ ì¤‘ ë¹¨ê°„ ì ì˜ ê°¯ìˆ˜ê°€ ë” ë§ì•„ì§€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ì´ê²ƒì´ ë°”ë¡œ KNNì˜ í•µì‹¬ ì•„ì´ë””ì–´ ì…ë‹ˆë‹¤. ë§Œì•½ classê°€ ì´ë¯¸ ë¶„ë¥˜ëœ íŠ¹ì • ë°ì´í„°ì…‹ì„ ë³´ìœ í•˜ê³  ìˆë‹¤ë©´, classê°€ ë¶„ë¥˜ë˜ì§€ ì•Šì€ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ í˜„ì¬ ë°ì´í„°ì…‹ê³¼ ë¹„êµí•˜ì—¬ ë¶„ë¥˜í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒì„ ì°¾ì•„ëƒ„ìœ¼ë¡œì¨ ë§ì´ì£ .

# Introduction

KNN ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•œ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ í•œ ê°€ì§€ ì˜ˆì‹œë¥¼ ë“¤ì–´ë´…ì‹œë‹¤. ì˜í™” ë°ì´í„°ì…‹ìœ¼ë¡œ ì˜ˆë¥¼ ë“¤ë©´, ì˜í™” ë°ì´í„° í¬ì¸íŠ¸, ì¦‰ ê° ì˜í™”ì— ëŒ€í•œ featureë¡œëŠ” ì˜í™”ì˜ ìƒì˜ ì‹œê°„, ê·¸ë¦¬ê³  ì´¬ì˜ì— ë“  ì˜ˆì‚°ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ë ‡ê²Œ ë‘ featureë¥¼ í™œìš©í•œë‹¤ë©´ ì˜í™” ë°ì´í„°ë¥¼ 2ì°¨ì› ê³µê°„ìƒì— ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ featureë¡œëŠ” ì—°ì†ì ì¸ ê°’ì´ ì•„ë‹Œ boolean featureê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Black ë˜ëŠ” White ì˜í™”ì¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” featureê°€ True, False ê°’ì„ ê°€ì§ˆ ìˆ˜ ìˆê³  ê°ë…ì´ Stanley Kubrickì´ëƒ ì•„ë‹ˆëƒì— ë”°ë¼ì„œ True, False ê°’ì„ ê°€ì§ˆ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ì˜í™”ì˜ ëŸ¬ë‹ íƒ€ì„, ì œì‘ëœ ì—°ë„, íˆ¬ì…ëœ ì˜ˆì‚° ì •ë³´ë¥¼ ê°€ì§€ê³  IMDb ratingì´ 7.0ì„ ë„˜ëŠëƒ ëª» ë„˜ëŠëƒì— ë”°ë¼ì„œ 'good' ë˜ëŠ” 'bad'ë¡œ classify í•˜ëŠ” KNN ì•Œê³ ë¦¬ì¦˜ì„ ì‘ì„±í•´ë³´ë„ë¡ í•˜ê³˜ìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ê³¼ ë ˆì´ë¸”ì˜ ëª¨ì–‘ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```python
# ë°ì´í„°ì…‹ì€ ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœì˜ JSON íŒŒì¼ì…ë‹ˆë‹¤
# 'ì˜í™” ì œëª©': [ì •ê·œí™”ëœ íˆ¬ì…ëœ ì˜ˆì‚°, ì •ê·œí™”ëœ ëŸ¬ë‹ íƒ€ì„, ì •ê·œí™”ëœ ì œì‘ ì—°ë„] ê°’ì„ key-valueë¡œ ê°€ì§‘ë‹ˆë‹¤
'''
{
  'Mountain': [0.0011460670664191085, 0.3310580204778157, 0.8764044943820225],
  'Clueless': [0.000982340650333614, 0.20477815699658702, 0.7640449438202247],
  'Far from Heaven': [0.0011051354623977348, 0.23890784982935154, 0.8426966292134831]
}
'''
# ë ˆì´ë¸”ì€ ê° ì˜í™”ê°€ IMDb í‰ì  7.0ì„ ë„˜ëŠëƒì— ë”°ë¼ 1(good, ë„˜ê¹€)ê³¼ 0(bad, ëª» ë„˜ê¹€)ìœ¼ë¡œ ë¶„ë¦¬í•œ JSON íŒŒì¼ì…ë‹ˆë‹¤
# 'ì˜í™” ì œëª©': 'IMDb í‰ì  7.0 ë„˜ê¹€ ì—¬ë¶€' ê°’ì„ key-valueë¡œ ê°€ì§‘ë‹ˆë‹¤
'''
{
  'The Gallows': 0,
  'Hollywood Shuffle': 1,
  'The Lost Skeleton of Cadavra': 1,
}
'''
from movies import movie_dataset, movie_labels
```

# Distance Between Points

KNN ì•Œê³ ë¦¬ì¦˜ì—ì„œ íŠ¹ì • ë°ì´í„° í¬ì¸íŠ¸ì˜ ê°€ê¹Œìš´ ì´ì›ƒì„ ì•Œê¸° ìœ„í•´ì„  ë¨¼ì € íŠ¹ì • ë°ì´í„° í¬ì¸íŠ¸ë¡œë¶€í„° ê°ê°ì˜ ë°ì´í„° í¬ì¸íŠ¸ê¹Œì§€ì— ëŒ€í•œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ _Star Wars_ ì˜ ëŸ¬ë‹íƒ€ì„ì´ 125ë¶„, ì œì‘ ì—°ë„ê°€ 1977ë…„ì´ê³  _Raiders of the Lost Ark_ ì˜ ëŸ¬ë‹íƒ€ì„ì´ 115ë¶„, ì œì‘ ì—°ë„ê°€ 1981ë…„ì´ë¼ë©´ ë‘ ì˜í™”ê°„ì˜ ê±°ë¦¬ëŠ” ì–´ë–»ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆì„ê¹Œìš”? ê³µì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

$$\sqrt {(125 - 115)^2 + (1977 - 1981)^2} = 10.77$$

ê·¸ëŸ¬ë‚˜ ìœ„ì™€ ê°™ì´ ëŸ¬ë‹ íƒ€ì„ê³¼ ì—°ë„ë§Œìœ¼ë¡œ ë‘ ì˜í™” ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ì¸¡ì •í•˜ëŠ” ê²ƒì€ ì•„ë¬´ë˜ë„ ì•½ê°„ ì œí•œì ì…ë‹ˆë‹¤. ë§ì€ ë³€ìˆ˜ë“¤ì´ ì¡´ì¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ì£ . ë§Œì•½ ìƒˆë¡œìš´ ë³€ìˆ˜ê°€ ì¶”ê°€ë˜ì–´ì„œ 2ì°¨ì›ì´ ì•„ë‹Œ 3ì°¨ì› ìƒì—ì„œ ë°ì´í„°ê°„ì˜ ê±°ë¦¬ë¥¼ ì¸¡ì •í•´ì•¼í•  ë–„ëŠ” ì–´ë–»ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆì„ê¹Œìš”? ë˜ 3ì°¨ì›ì„ ë„˜ì–´ì„œ Nì°¨ì› ìƒì˜ ì ë“¤ ì‚¬ì´ì˜ ê±°ë¦¬ëŠ” ì–´ë–»ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆì„ê¹Œìš”? Nì°¨ì› ìƒì˜ ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ëŠ” ì¼ë°˜í™”ëœ ê³µì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

$$\sqrt{(A_1 - B_1)^2 + (A_2 - B_2)^2 + \cdots + (A_n - B_n)^2}$$

ìœ„ ê³µì‹ì„ ì´ìš©í•˜ì—¬, ìš°ë¦¬ëŠ” Nì°¨ì›ì˜ ì ì˜ K-Nearest Neighborsë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Python code

ì˜í™” ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” ë‘ ë°°ì—´ì„ ë°›ì•„ì„œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•œ í›„ ì´ë¥¼ ë°˜í™˜í•˜ëŠ” `distance()` í•¨ìˆ˜ë¥¼ python ì½”ë“œë¡œ êµ¬í˜„í•´ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```python
# movie1ê³¼ movie2ëŠ” [íˆ¬ì…ëœ ì˜ˆì‚°, ëŸ¬ë‹ íƒ€ì„, ì œì‘ ì—°ë„] ì„ ì €ì¥í•˜ëŠ” ë°°ì—´ì…ë‹ˆë‹¤
def distance(movie1, movie2):
  distance = sum([ (movie1[i] - movie2[i])**2 for i in range(len(movie1))]) ** 0.5
  return distance
```

# Normalization

ì¼ë°˜ì ìœ¼ë¡œ KNNì•Œê³ ë¦¬ì¦˜ì˜ ê³„ì‚° ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. **Normalize the data**
2. Find the `k` nearest neighbors
3. Classify the new point based on those neighbors

ë§Œì•½ ì˜í™”ë¥¼ ì œì‘í•˜ëŠ”ë° íˆ¬ì…ë˜ëŠ” ì˜ˆì‚°ì„ featureë¡œ í™œìš©í•œë‹¤ë©´, ë°ì´í„°ì— ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜í™” ì œì‘ ì—°ë„ featureëŠ” ìµœëŒ€ê°’ê³¼ ìµœì†Œê°’ì˜ ì°¨ì´ê°€ ë‹¨ì§€ 125ë…„ ë°–ì— ë˜ì§€ ì•ŠëŠ”ë°, ì˜í™” ì œì‘ ì˜ˆì‚°ì€ ëª‡ ë°±ë§Œ ë‹¬ëŸ¬ê°€ ë  ìˆ˜ ìˆê¸° ë–„ë¬¸ì…ë‹ˆë‹¤.

ì´ëŠ” ê±°ë¦¬ ê³„ì‚° ê³µì‹ì´ ëª¨ë“  ì°¨ì›ì„ ë™ë“±í•˜ê²Œ ë‹¤ë£¨ê¸° ë•Œë¬¸ì— ë°œìƒí•©ë‹ˆë‹¤. ê° ì°¨ì›ì˜ ìŠ¤ì¼€ì¼ì„ ê³ ë ¤í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì´ì£ . ë§Œì•½ ë‘ ì˜í™”ê°„ì˜ ì œì‘ ì—°ë„ê°€ 70ë…„ì´ ì°¨ì´ê°€ ë‚œë‹¤ë©´ ì´ëŠ” ê½¤ í° ì°¨ì´ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì§€ê¸ˆìœ¼ë¡œì„  ì´ëŠ” ì˜í™” ì œì‘ì— íˆ¬ì…ëœ ì˜ˆì‚°ì´ 70ë‹¬ëŸ¬ ë°–ì— ì°¨ì´ê°€ ë‚˜ì§€ ì•ŠëŠ” ê²ƒê³¼ ë™ì¼í•œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ì œì‘ ì—°ë„ê°€ 1ë…„ ì°¨ì´ë‚˜ëŠ” ê²ƒì´ íˆ¬ì…ëœ ì—ì‚° 1ë‹¬ëŸ¬ ì°¨ì´ë‚˜ëŠ” ê²ƒê³¼ ê°™ì€ ê²ƒì´ì£ ... ì¢€ ë§ì´ ì•ˆë˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.

ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„  ë°ì´í„°ë¥¼ Normalization(ì •ê·œí™”)í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ëª¨ë“  ê°’ë“¤ì´ 0ê³¼ 1ì‚¬ì´ì— ì˜¤ë„ë¡ ë§Œë“œëŠ” min-max normalizationì„ í™œìš©í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

## Python code

min-max normalizationì„ python ì½”ë“œë¡œ êµ¬í˜„í•´ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```python
# ì •ê·œí™”í•˜ê³ ì í•˜ëŠ” ê°’ì„ ì§€ë‹Œ ë°°ì—´ì„ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤
def min_max_normalize(lst):
  minimum, maximum  = [min(lst), max(lst)]
  normalized = []
  for value in lst:
    # ê° valueë¥¼ ì •ê·œí™”í•œ ê°’ì„ normalizedì— ì¶”ê°€í•©ë‹ˆë‹¤
    normalized.append((value - minimum) / (maximum - minimum))

  return normalized	# ì •ê·œí™”ëœ ë°°ì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤
```

# Finding the Nearest Neighbors

ì´ì œ KNN ì•Œê³ ë¦¬ì¦˜ì— í•„ìš”í•œ ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. Normalize the data
2. **Find the `k` nearest neighbors**
3. Classify the new point based on those neighbors

ì´ì œ ìš°ë¦¬ëŠ” ë°ì´í„°ê°„ ê±°ë¦¬ë¥¼ ì¸¡ì •í•˜ê³  ì •ê·œí™”í•˜ëŠ” ë°©ë²•ì„ ì•Œê²Œ ë˜ì—ˆìœ¼ë‹ˆ ì„ì˜ì˜ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„  ë¨¼ì € ì„ì˜ì˜ ë°ì´í„°ì™€ ê°€ì¥ ê°€ê¹Œìš´ `k` ê°œì˜ ì´ì›ƒì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. ì¼ë‹¨ `k` ë¥¼ 5ë¼ê³  í•´ë´…ì‹œë‹¤.

ê°€ê¹Œìš´ 5ê°œì˜ ì´ì›ƒì„ ì°¾ê¸° ìœ„í•´ì„ , ì„ì˜ì´ unknownë°ì´í„°ì™€ ë‹¤ë¥¸ ëª¨ë“  ë°ì´í„°ê°„ì˜ ê±°ë¦¬ë¥¼ ë¹„êµí•´ì•¼í•©ë‹ˆë‹¤. ì¦‰, unknownë°ì´í„°ì™€ ë‹¤ë¥¸ ê°ê°ì˜ ë°ì´í„°ì— ëŒ€í•´ ê±°ë¦¬ë¥¼ ë‹¤ ê³„ì‚°í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê¶ê·¹ì ìœ¼ë¡œ ê° ì˜í™”ì™€ í•´ë‹¹ ì˜í™”ì™€ì˜ ê±°ë¦¬ë¥¼ ì •ë ¬í•œ ë°°ì—´ì„ ì–»ì„ ê²ƒì…ë‹ˆë‹¤.

```python
[
  [0.30, 'Superman II'],
  [0.31, 'Finding Nemo'],
  ...
  ...
  [0.38, 'Blazing Saddles']
]
```

ìœ„ì˜ ì˜ˆì—ì„œëŠ” ì„ì˜ì˜ unknownì˜í™”ì™€ Superman II ì™€ì˜ ê±°ë¦¬ëŠ” 0.3 ì…ë‹ˆë‹¤.

## Python code

ì„ì˜ì˜ unknown ë°ì´í„°ì™€ ëª¨ë“  ë°ì´í„° í¬ì¸íŠ¸ì™€ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ê³ , ì´ë¥¼ ì •ë ¬í•˜ì—¬ ê°€ì¥ ê°€ê¹Œìš´ `k` ê°œì˜ ì´ì›ƒì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ `classify()` ë¥¼ python ì½”ë“œë¡œ êµ¬í˜„í•´ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```python
def classify(unknown, dataset, k):
  distances = []
  for title in dataset:
    # [unknown ë°ì´í„°ì™€ íŠ¹ì • ì˜í™”ì™€ì˜ ê±°ë¦¬, ì˜í™” ì œëª©] ì„ distances ë°°ì—´ì— ì¶”ê°€í•©ë‹ˆë‹¤
    distances.append([distance(unknown, dataset[title]), title])
  distances.sort()	# ê±°ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ distances ë°°ì—´ì„ ì •ë ¬í•©ë‹ˆë‹¤

  return distances[:k]	# ê°€ì¥ ê°€ê¹Œìš´ k ê°œì˜ neighborsë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤
```

# Count Neighbors

ì´ì œ KNN ì•Œê³ ë¦¬ì¦˜ì— í•„ìš”í•œ ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. Normalize the data
2. Find the `k` nearest neighbors
3. **Classify the new point based on those neighbors**

ê°€ì¥ ê°€ê¹Œìš´ `k` ê°œì˜ ì´ì›ƒì„ êµ¬í–ˆìœ¼ë‹ˆ, ì´ì›ƒ ì˜í™”ì˜ í‰ì ì— ë”°ë¼ unknownì˜í™”ê°€ 'good' ì¸ì§€ 'bad' ì¸ì§€ ë¶„ë¥˜í•´ ë³´ë„ë¡ í•©ì‹œë‹¤. ê³¼ë°˜ìˆ˜ë¥¼ ë„˜ëŠ” ê²°ê³¼ë¥¼ ë”°ë¼ê°€ê²Œ í•˜ê³ , ë§Œì•½ `k` ê°€ ì§ìˆ˜ì—¬ì„œ 'good' ê³¼ 'bad' ê°€ 1ëŒ€1 ë¡œ ë‚˜ì˜¨ë‹¤ë©´ ì´ ë•Œ unknown ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ê²°ì •í• ì§€ ì¶”ê°€ì ì¸ ë¡œì§ì´ í•„ìš”í•˜ê²Œ ë©ë‹ˆë‹¤. ì—¬ëŸ¬ ë¡œì§ì´ ì¡´ì¬í•˜ì§€ë§Œ, ì´ ê²½ìš°ì—” ê°€ì¥ ê°€ê¹Œìš´ ì ì˜ í´ë˜ìŠ¤ë¥¼ ë¶€ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Python code

ìœ„ì—ì„œ ì‘ì„±í•œ `classify()` í•¨ìˆ˜ë¥¼ ë§ˆì € ì‘ì„±í•´ì„œ neighborsì— ë”°ë¼ classë¥¼ ë¶„ë¥˜í•˜ë‹¤ë¡ í•©ì‹œë‹¤. ì´ ë•Œ ì´ì›ƒì— ëŒ€í•œ labelsì´ í•„ìš”í•˜ë‹ˆ ì´ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ì„ ìˆ˜ ìˆë„ë¡ ì¶”ê°€í•´ì¤ì‹œë‹¤.

```python
# ì„¸ ë²ˆì§¸ íŒŒë¼ë¯¸í„°ë¡œ labelsë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤
def classify(unknown, dataset, labels, k):
  distances = []
  for title in dataset:
    # [unknown ë°ì´í„°ì™€ íŠ¹ì • ì˜í™”ì™€ì˜ ê±°ë¦¬, ì˜í™” ì œëª©] ì„ distances ë°°ì—´ì— ì¶”ê°€í•©ë‹ˆë‹¤
    distances.append([distance(unknown, dataset[title]), title])
  distances.sort()	# ê±°ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ distances ë°°ì—´ì„ ì •ë ¬í•©ë‹ˆë‹¤
  # ---ì¶”ê°€---
  neighbors = distances[:k]	# ê°€ì¥ ê°€ê¹Œìš´ kê°œì˜ ì´ì›ƒì„ neightborsì— ì €ì¥í•©ë‹ˆë‹¤
  num_good, num_bad = [0, 0]	# ì´ì›ƒì˜ good, bad ì—¬ë¶€ë¥¼ ì„¸ëŠ” ë³€ìˆ˜ë¥¼ ì„ ì–¸í•©ë‹ˆë‹¤
  for neighbor in neighbors:
    title = neighbor[1]
    if labels[title] == 1:	# ë§Œì•½ ì´ì›ƒ ì˜í™”ê°€ good ì´ë¼ë©´
      num_good += 1	# num_good ì„ 1 ì¦ê°€ì‹œí‚µë‹ˆë‹¤
     else labels[title] == 0:	# ë§Œì•½ ì´ì›ƒ ì˜í™”ê°€ bad ë¼ë©´
      num_bad += 0	# num_bad ë¥¼ 1 ì¦ê°€ì‹œí‚µë‹ˆë‹¤

  return 1 if num_good > num_bad else 0
```

# Classify Your Favorite Movie

ì, ì´ì œ ì¢‹ì•„í•˜ëŠ” ì˜í™”ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë´…ì‹œë‹¤. ì €ëŠ” 2017ë…„ì— ì œì‘ëœ _Call Me By Your Name_ ì´ë€ ì˜í™”ë¡œ í…ŒìŠ¤íŠ¸í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë¨¼ì € í•´ë‹¹ ì˜í™”ê°€ ë°ì´í„°ì…‹ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤.

```python
print('Call Me By Your Name' in movie_dataset)	# False
```

ë‹¤í–‰íˆ í…ŒìŠ¤íŠ¸ í•˜ë ¤ëŠ” ì˜í™”ëŠ” ë°ì´í„°ì…‹ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ì œ ì´ unknown ë°ì´í„°ê°€ ì–´ë–»ê²Œ ë¶„ë¥˜ë  ì§€ ì•Œì•„ë´…ì‹œë‹¤. _Call Me By Your Name_ ì€ ëŸ¬ë‹ íƒ€ì„ì´ 132ë¶„ì´ê³ , 2017ë…„ì— ì œì‘ë˜ì—ˆìœ¼ë©° ì´ 350,000 ë‹¬ëŸ¬ê°€ íˆ¬ì…ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì˜í™”ì˜ ê° featureê°’ë“¤ì„ ì •ê·œí™”í•œ ë’¤ `my_movie` ì— ì €ì¥í•©ì‹œë‹¤.

```python
my_movie = min_max_normalize([350000, 132, 2017])
```

ì´ì œ í•´ë‹¹ ì˜í™”ë¥¼ classify í•´ë´…ì‹œë‹¤. ì´ ë•Œ `k` ê°’ì€ 5ë¡œ ì„¤ì •í•´ë´…ì‹œë‹¤.

```python
print(classify(normalized_my_movie, movie_dataset, movie_labels, 5))	# 1
```

ê²°ê³¼ê°€ 1ë¡œ ë‚˜ì™”ìŠµë‹ˆë‹¤. ì¦‰, ì´ ì˜í™”ëŠ” IMDb í‰ì ì´ 7.0 ë³´ë‹¤ ë†’ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ì´ ì•Œê³ ë¦¬ì¦˜ì„ ë¯¿ì„ ìˆ˜ ìˆëŠ” ê²ƒì¼ê¹Œìš”?

# Training and Validation Sets

ìš°ë¦¬ê°€ ìœ„ì—ì„œ ì‘ì„±í•œ ì•Œê³ ë¦¬ì¦˜ì´ ê³¼ì—° ì–¼ë§ˆë‚˜ ì •í™•í•œì§€ ì•Œì•„ë³¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ê¸° ìœ„í•´ì„  ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ì…‹ì„ training setê³¼ validation/test setìœ¼ë¡œ ë‚˜ëˆ„ì–´ì•¼ í•©ë‹ˆë‹¤.

ê·¸ëŸ° ë‹¤ìŒ, validation setì˜ ê° ë°ì´í„°ë¥¼ KNN ì•Œê³ ë¦¬ì¦˜ì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•˜ê³ , ëª¨ë“  training setì˜ ë°ì´í„°ì™€ì˜ ê±°ë¦¬ë¥¼ êµ¬í•œ ë’¤, K Nearest Neighborsë¥¼ êµ¬í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ í•´ë‹¹ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ validation setì˜ ë°ì´í„°ì˜ classë¥¼ predictí•œ ë’¤, validation setì˜ labelê³¼ ë¹„êµí•¨ìœ¼ë¡œì¨ ì–¼ë§ˆë‚˜ ì˜¬ë°”ë¥´ê²Œ ì¸¡ì •í•˜ì˜€ëŠ”ì§€ validation_accuracyë¥¼ ê³„ì‚°í•  ê²ƒì…ë‹ˆë‹¤.

## Python code

ë¨¼ì €, ì´ë¯¸ training_setê³¼ validation_setì´ ë‚˜ëˆ„ì–´ì ¸ ìˆë‹¤ê³  ê°€ì •í•©ì‹œë‹¤. validation_setì˜ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì˜ˆì¸¡í•˜ì˜€ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” validation_accuracyë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ `find_validation_accuracy()` ë¥¼ ì‘ì„±í•´ë´…ì‹œë‹¤.

```python
# ëª¨ë“  validation set ë°ì´í„°ì— ëŒ€ë˜ì„œ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜í•œ ë°ì´í„°ì˜ ê°¯ìˆ˜ë¥¼
# ëª¨ë“  validation set ë°ì´í„°ì˜ ê°œìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤
def find_validation_accuracy(training_set, training_labels, validation_set, validation_labels, k):
  num_correct = 0.0

  for title in validation_set:
    movie = validation_set[title]
    guess = classify(movie, training_set, training_labels, k)
    if(guess == validation_labels[title]):
      num_correct += 1

  return num_correct / len(validation_set)
```

# Graph of K

ì•„ë˜ì˜ ê·¸ë¦¼ì€ `k` ì— ë”°ë¼ validation accuracyê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ê³  ìˆìŠµë‹ˆë‹¤.

<img width="500" src="https://s3.amazonaws.com/codecademy-content/courses/learn-knn/k.png" />

`k` ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë°ì´í„°ì— overfitting ë˜ê³ , ë°˜ëŒ€ë¡œ `k` ê°€ ë„ˆë¬´ ë†’ìœ¼ë©´ ë°ì´í„°ë¥¼ ì˜ í•™ìŠµí•˜ì§€ ëª»í•´ underfitting ë©ë‹ˆë‹¤. ìœ„ ê²½ìš°ì—ì„  kê°€ 75ì¼ ë•Œ ì œì¼ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.

# Using sklearn

ìœ„ì—ì„œ êµ¬í˜„í•œ ëª¨ë“  ë‚´ìš©ì„ `sklearn` ì—ì„œ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. `sklearn` ì€ MLì„ ìœ„í•œ ë©”ì„œë“œë¥¼ ì œê³µí•˜ëŠ” Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. KNNì„ ì ìš©í•˜ê¸° ìœ„í•´ì„  `KNeighborsClassifier` ê°ì²´ë¥¼ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ `k` ê°’ì„ ì„¤ì •í•´ ì£¼ì–´ì•¼ í•˜ëŠ”ë°, ì´ëŠ” `n_neighbors` ì˜µì…˜ìœ¼ë¡œ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
classifier = KNeighborsClassifier(n_neighbors = 3)
```

ê·¸ëŸ° ë‹¤ìŒ, ìš°ë¦¬ì˜ classifierë¥¼ í•™ìŠµì‹œì¼œì•¼ í•©ë‹ˆë‹¤. `.fit()` ë©”ì„œë“œì— ë‘ íŒŒë¼ë¯¸í„°ë¡œ training_set ê³¼ training_labelì„ ë„˜ê²¨ì£¼ë©´ ë©ë‹ˆë‹¤.

```python
training_points = [
  [0.5, 0.2, 0.1],
  [0.9, 0.7, 0.3],
  [0.4, 0.5, 0.7]
]

training_labels = [0, 1, 1]
classifier.fit(training_points, training_labels)
```

ë§ˆì§€ë§‰ìœ¼ë¡œ, í•™ìŠµì„ ì‹œí‚¨ ë’¤ `.predict()` ë©”ì„œë“œì— íŒŒë¼ë¯¸í„°ë¡œ test_setì„ ë„˜ê²¨ì£¼ì–´ unknown ë°ì´í„°ë¥¼ classify í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
unknown_points = [
  [0.2, 0.1, 0.7],
  [0.4, 0.7, 0.6],
  [0.5, 0.8, 0.1]
]

guesses = classifier.predict(unknown_points
```

ì´ì œ ìš°ë¦¬ê°€ ì§€ê¸ˆê» ì‘ì„±í•œ ì½”ë“œë¥¼ `sklearn` ìœ¼ë¡œ implement í•´ë´…ì‹œë‹¤.

```python
from movies import movie_dataset, labels
from sklearn.neighbors import KNeighborsClassifier

classifier = KNeighborsClassifier(n_neighbors = 5)
classifier.fit(movie_dataset, labels)

print(classifier.predict(
  [
    [.45, .2, .5],
    [.25, .8, .9],
    [.1, .1, .9]
  ]
))	# 1 1 0
```

# Review

ì§€ê¸ˆê¹Œì§€ K-Nearest Neighbors ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œ ë°°ìš´ ë‚´ìš©ì„ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

- Data with `n` features can be conceptualized as points lying in n-dimensional space.
- Data points can be compared by using the distance formula. Data points that are similar will have a smaller distance between them.
- A point with an unknown class can be classified by finding the `k` nearest neighbors
- To verify the effectiveness of a classifier, data with known classes can be split into a training set and a validation set. Validation error can then be calculated.
- Classifiers have parameters that can be tuned to increase their effectiveness. In the case of K-Nearest Neighbors, `k` can be changed.
- A classifier can be trained improperly and suffer from overfitting or underfitting. In the case of K-Nearest Neighbors, a low `k` often leads to overfitting and a large `k` often leads to underfitting.
- Pythonâ€™s sklearn library can be used for many classification and machine learning algorithms.

ê·¸ëŸ°ë° ì—¬ê¸°ì„œ í•œê°€ì§€ ì¬ë°ŒëŠ” ì‚¬ì‹¤, KNNìœ¼ë¡œ classification ë¿ë§Œ ì•„ë‹ˆë¼ regression ë¬¸ì œë„ í’€ ìˆ˜ ìˆë‹¤ëŠ” ê±¸ ì•„ì‹œë‚˜ìš”?ğŸ˜³ ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ì„œëŠ” KNNìœ¼ë¡œ regression í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ì„œ ì‘ì„±í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤ :)

# References

- [Codecademy](http://www.codecademy.com)
